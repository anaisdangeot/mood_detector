{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>artist</th>\n",
       "      <th>seq</th>\n",
       "      <th>song</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>No, no\\r\\nI ain't ever trapped out the bando\\r...</td>\n",
       "      <td>Everyday</td>\n",
       "      <td>0.626</td>\n",
       "      <td>aint ever trap bando oh lord dont get wrong kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>The drinks go down and smoke goes up, I feel m...</td>\n",
       "      <td>Live Till We Die</td>\n",
       "      <td>0.630</td>\n",
       "      <td>drink go smoke go feel get let go care get los...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>She don't live on planet Earth no more\\r\\nShe ...</td>\n",
       "      <td>The Otherside</td>\n",
       "      <td>0.240</td>\n",
       "      <td>dont live planet earth find love venus thats w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>Trippin' off that Grigio, mobbin', lights low\\...</td>\n",
       "      <td>Pinot</td>\n",
       "      <td>0.536</td>\n",
       "      <td>trippin grigio mobbin light low trippin grigio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Elijah Blake</td>\n",
       "      <td>I see a midnight panther, so gallant and so br...</td>\n",
       "      <td>Shadows &amp; Diamonds</td>\n",
       "      <td>0.371</td>\n",
       "      <td>see midnight panther gallant brave find find a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0        artist  \\\n",
       "0             0           0  Elijah Blake   \n",
       "1             1           1  Elijah Blake   \n",
       "2             2           2  Elijah Blake   \n",
       "3             3           3  Elijah Blake   \n",
       "4             4           4  Elijah Blake   \n",
       "\n",
       "                                                 seq                song  \\\n",
       "0  No, no\\r\\nI ain't ever trapped out the bando\\r...            Everyday   \n",
       "1  The drinks go down and smoke goes up, I feel m...    Live Till We Die   \n",
       "2  She don't live on planet Earth no more\\r\\nShe ...       The Otherside   \n",
       "3  Trippin' off that Grigio, mobbin', lights low\\...               Pinot   \n",
       "4  I see a midnight panther, so gallant and so br...  Shadows & Diamonds   \n",
       "\n",
       "   label                                     cleaned_lyrics  \n",
       "0  0.626  aint ever trap bando oh lord dont get wrong kn...  \n",
       "1  0.630  drink go smoke go feel get let go care get los...  \n",
       "2  0.240  dont live planet earth find love venus thats w...  \n",
       "3  0.536  trippin grigio mobbin light low trippin grigio...  \n",
       "4  0.371  see midnight panther gallant brave find find a...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/home/anais/code/anaisdangeot/mood_detector/raw_data/labeled_lyrics_cleaned_processed.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cleaned_lyrics'].isna().sum()\n",
    "data['cleaned_lyrics'] = data['cleaned_lyrics'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub = data.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5230\n",
       "1    4770\n",
       "Name: mood, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cat_valence(row):\n",
    "    if row >= 0.5:\n",
    "        return 1\n",
    "    elif row <0.5:\n",
    "        return 0\n",
    "    else:\n",
    "        return None\n",
    "data_sub['mood'] = data_sub['label'].apply(lambda x:cat_valence(x))\n",
    "data_sub['mood'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Feature/Target\n",
    "X = data_sub['cleaned_lyrics'].apply(lambda x: np.str_(x))\n",
    "y = data_sub[\"mood\"]\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline using logistic regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Pipeline vectorizer + Naive Bayes\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(), \n",
    "    LogisticRegression()\n",
    ")\n",
    "\n",
    "# Cross-validation\n",
    "cv_results = cross_validate(pipeline, X_train, y_train, cv = 5, scoring = [\"accuracy\"])\n",
    "average_accuracy = cv_results[\"test_accuracy\"].mean()\n",
    "baseline_accuracy = np.round(average_accuracy,2)\n",
    "baseline_accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the grid of parameters\n",
    "parameters = {\n",
    "    'tfidfvectorizer__ngram_range': ((2,2), (1,2)),\n",
    "    'tfidfvectorizer__max_df': [0,25, 0.3, 0.35],\n",
    "    'tfidfvectorizer__max_features': [50],\n",
    "}\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    parameters,\n",
    "    scoring = \"accuracy\",\n",
    "    cv = 5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best score\n",
    "print(f\"Best Score = {grid_search.best_score_}\")\n",
    "\n",
    "# Best params\n",
    "print(f\"Best params = {grid_search.best_params_}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After different iterations, best params: max_df= 0.35, max_features=50, n_gram=(1,2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_df=0.35,max_features=50)\n",
    "\n",
    "vectorized_documents = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "lower not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 19\u001b[0m\n\u001b[1;32m     15\u001b[0m     X_pad \u001b[39m=\u001b[39m pad_sequences(X_token, dtype\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m'\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m     \u001b[39mreturn\u001b[39;00m X_pad, vocab_size\n\u001b[0;32m---> 19\u001b[0m X_pad, vocab_size \u001b[39m=\u001b[39m get_mock_up_data(vectorized_documents)\n\u001b[1;32m     20\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mX_pad.shape\u001b[39m\u001b[39m\"\u001b[39m, X_pad\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     21\u001b[0m X_pad\n",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m, in \u001b[0;36mget_mock_up_data\u001b[0;34m(vec_txt)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_mock_up_data\u001b[39m(vec_txt):\n\u001b[1;32m      7\u001b[0m     \u001b[39m### Let's tokenize the vocabulary \u001b[39;00m\n\u001b[1;32m      8\u001b[0m     tk \u001b[39m=\u001b[39m Tokenizer()\n\u001b[0;32m----> 9\u001b[0m     tk\u001b[39m.\u001b[39;49mfit_on_texts(vec_txt)\n\u001b[1;32m     10\u001b[0m     vocab_size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(tk\u001b[39m.\u001b[39mword_index)\n\u001b[1;32m     11\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mThere are \u001b[39m\u001b[39m{\u001b[39;00mvocab_size\u001b[39m}\u001b[39;00m\u001b[39m different words in your corpus\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/keras/preprocessing/text.py:293\u001b[0m, in \u001b[0;36mTokenizer.fit_on_texts\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    292\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39manalyzer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 293\u001b[0m         seq \u001b[39m=\u001b[39m text_to_word_sequence(\n\u001b[1;32m    294\u001b[0m             text,\n\u001b[1;32m    295\u001b[0m             filters\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilters,\n\u001b[1;32m    296\u001b[0m             lower\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlower,\n\u001b[1;32m    297\u001b[0m             split\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msplit,\n\u001b[1;32m    298\u001b[0m         )\n\u001b[1;32m    299\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    300\u001b[0m         seq \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39manalyzer(text)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/keras/preprocessing/text.py:74\u001b[0m, in \u001b[0;36mtext_to_word_sequence\u001b[0;34m(input_text, filters, lower, split)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Converts a text to a sequence of words (or tokens).\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \n\u001b[1;32m     48\u001b[0m \u001b[39mDeprecated: `tf.keras.preprocessing.text.text_to_word_sequence` does not\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39m    A list of words (or tokens).\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[39mif\u001b[39;00m lower:\n\u001b[0;32m---> 74\u001b[0m     input_text \u001b[39m=\u001b[39m input_text\u001b[39m.\u001b[39;49mlower()\n\u001b[1;32m     76\u001b[0m translate_dict \u001b[39m=\u001b[39m {c: split \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m filters}\n\u001b[1;32m     77\u001b[0m translate_map \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m\u001b[39m.\u001b[39mmaketrans(translate_dict)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/scipy/sparse/_base.py:771\u001b[0m, in \u001b[0;36mspmatrix.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgetnnz()\n\u001b[1;32m    770\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(attr \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m not found\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: lower not found"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "### Let's create some mock data\n",
    "def get_mock_up_data(vec_txt):\n",
    "    ### Let's tokenize the vocabulary \n",
    "    tk = Tokenizer()\n",
    "    tk.fit_on_texts(vec_txt)\n",
    "    vocab_size = len(tk.word_index)\n",
    "    print(f'There are {vocab_size} different words in your corpus')\n",
    "    X_token = tk.texts_to_sequences(vec_txt)\n",
    "\n",
    "    ### Pad the inputs\n",
    "    X_pad = pad_sequences(X_token, dtype='float32', padding='post')\n",
    "    \n",
    "    return X_pad, vocab_size\n",
    "\n",
    "X_pad, vocab_size = get_mock_up_data(vectorized_documents)\n",
    "print(\"X_pad.shape\", X_pad.shape)\n",
    "X_pad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DL model using RNN (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 100)         2627600   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 20)                9680      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,637,301\n",
      "Trainable params: 2,637,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### Let's build the neural network now\n",
    "from tensorflow.keras import layers, Sequential\n",
    "\n",
    "# Size of your embedding space = size of the vector representing each word\n",
    "embedding_size = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(\n",
    "    input_dim=vocab_size+1, #+1 for the 0 padding\n",
    "    output_dim=embedding_size, # 100\n",
    "    mask_zero=True, # Built-in masking layer :)\n",
    "))\n",
    "\n",
    "model.add(layers.LSTM(20))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "175/175 [==============================] - 128s 700ms/step - loss: 0.6796 - accuracy: 0.5720 - val_loss: 0.6683 - val_accuracy: 0.6100\n",
      "Epoch 2/100\n",
      "175/175 [==============================] - 109s 624ms/step - loss: 0.6154 - accuracy: 0.6721 - val_loss: 0.6520 - val_accuracy: 0.6121\n",
      "Epoch 3/100\n",
      "175/175 [==============================] - 104s 595ms/step - loss: 0.5574 - accuracy: 0.7300 - val_loss: 0.6962 - val_accuracy: 0.6164\n",
      "Epoch 4/100\n",
      "175/175 [==============================] - 104s 595ms/step - loss: 0.5022 - accuracy: 0.7713 - val_loss: 0.6980 - val_accuracy: 0.6050\n",
      "Epoch 5/100\n",
      "175/175 [==============================] - 103s 586ms/step - loss: 0.4577 - accuracy: 0.8020 - val_loss: 0.7524 - val_accuracy: 0.5929\n",
      "Epoch 6/100\n",
      "175/175 [==============================] - 101s 580ms/step - loss: 0.4093 - accuracy: 0.8288 - val_loss: 0.7999 - val_accuracy: 0.5900\n",
      "Epoch 7/100\n",
      "175/175 [==============================] - 96s 549ms/step - loss: 0.3729 - accuracy: 0.8477 - val_loss: 0.8708 - val_accuracy: 0.5843\n",
      "Epoch 8/100\n",
      "175/175 [==============================] - 86s 491ms/step - loss: 0.3327 - accuracy: 0.8680 - val_loss: 0.9048 - val_accuracy: 0.5871\n",
      "Epoch 9/100\n",
      "175/175 [==============================] - 98s 562ms/step - loss: 0.3039 - accuracy: 0.8795 - val_loss: 0.9779 - val_accuracy: 0.5807\n",
      "Epoch 10/100\n",
      "175/175 [==============================] - 85s 488ms/step - loss: 0.2760 - accuracy: 0.8936 - val_loss: 1.0039 - val_accuracy: 0.5814\n",
      "Epoch 11/100\n",
      "175/175 [==============================] - 96s 551ms/step - loss: 0.2451 - accuracy: 0.9057 - val_loss: 1.0240 - val_accuracy: 0.5871\n",
      "Epoch 12/100\n",
      "175/175 [==============================] - 89s 508ms/step - loss: 0.2184 - accuracy: 0.9186 - val_loss: 1.0443 - val_accuracy: 0.5771\n",
      "Epoch 13/100\n",
      "175/175 [==============================] - 88s 505ms/step - loss: 0.2028 - accuracy: 0.9295 - val_loss: 1.1235 - val_accuracy: 0.5893\n",
      "Epoch 14/100\n",
      "175/175 [==============================] - 92s 529ms/step - loss: 0.1883 - accuracy: 0.9312 - val_loss: 1.1652 - val_accuracy: 0.5771\n",
      "Epoch 15/100\n",
      "175/175 [==============================] - 88s 502ms/step - loss: 0.1785 - accuracy: 0.9350 - val_loss: 1.2485 - val_accuracy: 0.5771\n",
      "Epoch 16/100\n",
      "175/175 [==============================] - 84s 477ms/step - loss: 0.1551 - accuracy: 0.9463 - val_loss: 1.2294 - val_accuracy: 0.5686\n",
      "Epoch 17/100\n",
      "175/175 [==============================] - 92s 527ms/step - loss: 0.1513 - accuracy: 0.9484 - val_loss: 1.3189 - val_accuracy: 0.5693\n",
      "Epoch 18/100\n",
      "175/175 [==============================] - 88s 505ms/step - loss: 0.1334 - accuracy: 0.9543 - val_loss: 1.3486 - val_accuracy: 0.5593\n",
      "Epoch 19/100\n",
      "175/175 [==============================] - 114s 653ms/step - loss: 0.1292 - accuracy: 0.9579 - val_loss: 1.3560 - val_accuracy: 0.5764\n",
      "Epoch 20/100\n",
      "175/175 [==============================] - 105s 600ms/step - loss: 0.1215 - accuracy: 0.9596 - val_loss: 1.4112 - val_accuracy: 0.5750\n",
      "Epoch 21/100\n",
      "175/175 [==============================] - 106s 607ms/step - loss: 0.1137 - accuracy: 0.9591 - val_loss: 1.3646 - val_accuracy: 0.5764\n",
      "Epoch 22/100\n",
      "175/175 [==============================] - 113s 646ms/step - loss: 0.1098 - accuracy: 0.9616 - val_loss: 1.4627 - val_accuracy: 0.5707\n",
      "Epoch 23/100\n",
      "175/175 [==============================] - 105s 598ms/step - loss: 0.1072 - accuracy: 0.9625 - val_loss: 1.4950 - val_accuracy: 0.5743\n",
      "Epoch 24/100\n",
      "175/175 [==============================] - 107s 608ms/step - loss: 0.0985 - accuracy: 0.9688 - val_loss: 1.4607 - val_accuracy: 0.5800\n",
      "Epoch 25/100\n",
      "175/175 [==============================] - 103s 587ms/step - loss: 0.0884 - accuracy: 0.9707 - val_loss: 1.5940 - val_accuracy: 0.5800\n",
      "Epoch 26/100\n",
      "175/175 [==============================] - 101s 580ms/step - loss: 0.0877 - accuracy: 0.9698 - val_loss: 1.6211 - val_accuracy: 0.5736\n",
      "Epoch 27/100\n",
      "175/175 [==============================] - 104s 597ms/step - loss: 0.0782 - accuracy: 0.9718 - val_loss: 1.6749 - val_accuracy: 0.5743\n",
      "Epoch 28/100\n",
      "175/175 [==============================] - 98s 558ms/step - loss: 0.0777 - accuracy: 0.9755 - val_loss: 1.6484 - val_accuracy: 0.5636\n",
      "Epoch 29/100\n",
      "175/175 [==============================] - 107s 614ms/step - loss: 0.0749 - accuracy: 0.9755 - val_loss: 1.6115 - val_accuracy: 0.5643\n",
      "Epoch 30/100\n",
      "175/175 [==============================] - 102s 580ms/step - loss: 0.0681 - accuracy: 0.9791 - val_loss: 1.7305 - val_accuracy: 0.5636\n",
      "Epoch 31/100\n",
      "175/175 [==============================] - 108s 616ms/step - loss: 0.0708 - accuracy: 0.9759 - val_loss: 1.7725 - val_accuracy: 0.5843\n",
      "Epoch 32/100\n",
      "175/175 [==============================] - 119s 682ms/step - loss: 0.0684 - accuracy: 0.9773 - val_loss: 1.6451 - val_accuracy: 0.5886\n",
      "Epoch 33/100\n",
      "175/175 [==============================] - 112s 641ms/step - loss: 0.0662 - accuracy: 0.9795 - val_loss: 1.7595 - val_accuracy: 0.5686\n",
      "Epoch 34/100\n",
      "175/175 [==============================] - 107s 613ms/step - loss: 0.0605 - accuracy: 0.9805 - val_loss: 1.7788 - val_accuracy: 0.5614\n",
      "Epoch 35/100\n",
      "175/175 [==============================] - 104s 593ms/step - loss: 0.0598 - accuracy: 0.9784 - val_loss: 1.6202 - val_accuracy: 0.5786\n",
      "Epoch 36/100\n",
      "175/175 [==============================] - 97s 554ms/step - loss: 0.0598 - accuracy: 0.9809 - val_loss: 1.7976 - val_accuracy: 0.5707\n",
      "Epoch 37/100\n",
      "175/175 [==============================] - 106s 606ms/step - loss: 0.0543 - accuracy: 0.9818 - val_loss: 1.8256 - val_accuracy: 0.5614\n",
      "Epoch 38/100\n",
      "175/175 [==============================] - 123s 704ms/step - loss: 0.0610 - accuracy: 0.9818 - val_loss: 1.7292 - val_accuracy: 0.5686\n",
      "Epoch 39/100\n",
      "175/175 [==============================] - 94s 539ms/step - loss: 0.0553 - accuracy: 0.9812 - val_loss: 1.7791 - val_accuracy: 0.5536\n",
      "Epoch 40/100\n",
      "175/175 [==============================] - 87s 496ms/step - loss: 0.0494 - accuracy: 0.9820 - val_loss: 1.8386 - val_accuracy: 0.5764\n",
      "Epoch 41/100\n",
      "175/175 [==============================] - 97s 556ms/step - loss: 0.0537 - accuracy: 0.9820 - val_loss: 1.9465 - val_accuracy: 0.5814\n",
      "Epoch 42/100\n",
      "175/175 [==============================] - 86s 494ms/step - loss: 0.0507 - accuracy: 0.9827 - val_loss: 1.8914 - val_accuracy: 0.5771\n",
      "Epoch 43/100\n",
      "175/175 [==============================] - 89s 510ms/step - loss: 0.0567 - accuracy: 0.9812 - val_loss: 1.8462 - val_accuracy: 0.5721\n",
      "Epoch 44/100\n",
      "175/175 [==============================] - 127s 722ms/step - loss: 0.0509 - accuracy: 0.9823 - val_loss: 1.8563 - val_accuracy: 0.5714\n",
      "Epoch 45/100\n",
      "175/175 [==============================] - 110s 631ms/step - loss: 0.0473 - accuracy: 0.9825 - val_loss: 1.8535 - val_accuracy: 0.5729\n",
      "Epoch 46/100\n",
      "175/175 [==============================] - 97s 553ms/step - loss: 0.0492 - accuracy: 0.9821 - val_loss: 1.9910 - val_accuracy: 0.5686\n",
      "Epoch 47/100\n",
      "175/175 [==============================] - 111s 637ms/step - loss: 0.0464 - accuracy: 0.9836 - val_loss: 1.9081 - val_accuracy: 0.5714\n",
      "Epoch 48/100\n",
      "175/175 [==============================] - 91s 520ms/step - loss: 0.0435 - accuracy: 0.9852 - val_loss: 2.0391 - val_accuracy: 0.5721\n",
      "Epoch 49/100\n",
      "175/175 [==============================] - 94s 536ms/step - loss: 0.0452 - accuracy: 0.9843 - val_loss: 1.8716 - val_accuracy: 0.5571\n",
      "Epoch 50/100\n",
      "175/175 [==============================] - 89s 510ms/step - loss: 0.0415 - accuracy: 0.9845 - val_loss: 1.8134 - val_accuracy: 0.5593\n",
      "Epoch 51/100\n",
      "175/175 [==============================] - 87s 497ms/step - loss: 0.0439 - accuracy: 0.9850 - val_loss: 1.9625 - val_accuracy: 0.5543\n",
      "Epoch 52/100\n",
      "175/175 [==============================] - 102s 581ms/step - loss: 0.0414 - accuracy: 0.9839 - val_loss: 1.9201 - val_accuracy: 0.5757\n",
      "Epoch 53/100\n",
      "175/175 [==============================] - 136s 776ms/step - loss: 0.0404 - accuracy: 0.9855 - val_loss: 1.8928 - val_accuracy: 0.5750\n",
      "Epoch 54/100\n",
      "175/175 [==============================] - 98s 560ms/step - loss: 0.0386 - accuracy: 0.9859 - val_loss: 1.9488 - val_accuracy: 0.5464\n",
      "Epoch 55/100\n",
      "175/175 [==============================] - 88s 506ms/step - loss: 0.0413 - accuracy: 0.9850 - val_loss: 2.0193 - val_accuracy: 0.5571\n",
      "Epoch 56/100\n",
      "175/175 [==============================] - 115s 655ms/step - loss: 0.0374 - accuracy: 0.9868 - val_loss: 2.0280 - val_accuracy: 0.5686\n",
      "Epoch 57/100\n",
      "175/175 [==============================] - 114s 653ms/step - loss: 0.0417 - accuracy: 0.9846 - val_loss: 1.9371 - val_accuracy: 0.5500\n",
      "Epoch 58/100\n",
      "175/175 [==============================] - 94s 534ms/step - loss: 0.0345 - accuracy: 0.9866 - val_loss: 2.0926 - val_accuracy: 0.5657\n",
      "Epoch 59/100\n",
      "175/175 [==============================] - 101s 578ms/step - loss: 0.0365 - accuracy: 0.9857 - val_loss: 2.0701 - val_accuracy: 0.5543\n",
      "Epoch 60/100\n",
      "175/175 [==============================] - 114s 652ms/step - loss: 0.0392 - accuracy: 0.9846 - val_loss: 1.9889 - val_accuracy: 0.5571\n",
      "Epoch 61/100\n",
      "175/175 [==============================] - 106s 603ms/step - loss: 0.0364 - accuracy: 0.9871 - val_loss: 2.1509 - val_accuracy: 0.5643\n",
      "Epoch 62/100\n",
      "175/175 [==============================] - 90s 514ms/step - loss: 0.0392 - accuracy: 0.9848 - val_loss: 2.2572 - val_accuracy: 0.5686\n",
      "Epoch 63/100\n",
      "175/175 [==============================] - 95s 543ms/step - loss: 0.0372 - accuracy: 0.9857 - val_loss: 1.9943 - val_accuracy: 0.5614\n",
      "Epoch 64/100\n",
      "175/175 [==============================] - 99s 565ms/step - loss: 0.0406 - accuracy: 0.9854 - val_loss: 1.9712 - val_accuracy: 0.5493\n",
      "Epoch 65/100\n",
      "175/175 [==============================] - 97s 555ms/step - loss: 0.0381 - accuracy: 0.9843 - val_loss: 2.0638 - val_accuracy: 0.5636\n",
      "Epoch 66/100\n",
      "175/175 [==============================] - 95s 541ms/step - loss: 0.0326 - accuracy: 0.9866 - val_loss: 2.2884 - val_accuracy: 0.5550\n",
      "Epoch 67/100\n",
      "175/175 [==============================] - 95s 542ms/step - loss: 0.0365 - accuracy: 0.9855 - val_loss: 2.1754 - val_accuracy: 0.5714\n",
      "Epoch 68/100\n",
      "175/175 [==============================] - 110s 626ms/step - loss: 0.0318 - accuracy: 0.9873 - val_loss: 1.9286 - val_accuracy: 0.5550\n",
      "Epoch 69/100\n",
      "175/175 [==============================] - 121s 692ms/step - loss: 0.0349 - accuracy: 0.9866 - val_loss: 2.1597 - val_accuracy: 0.5529\n",
      "Epoch 70/100\n",
      "175/175 [==============================] - 116s 662ms/step - loss: 0.0316 - accuracy: 0.9870 - val_loss: 2.1242 - val_accuracy: 0.5586\n",
      "Epoch 71/100\n",
      "175/175 [==============================] - 117s 668ms/step - loss: 0.0416 - accuracy: 0.9841 - val_loss: 2.0372 - val_accuracy: 0.5643\n",
      "Epoch 72/100\n",
      "175/175 [==============================] - 123s 706ms/step - loss: 0.0352 - accuracy: 0.9870 - val_loss: 2.0722 - val_accuracy: 0.5664\n",
      "Epoch 73/100\n",
      "175/175 [==============================] - 128s 734ms/step - loss: 0.0351 - accuracy: 0.9870 - val_loss: 2.0359 - val_accuracy: 0.5693\n",
      "Epoch 74/100\n",
      "175/175 [==============================] - 128s 733ms/step - loss: 0.0358 - accuracy: 0.9859 - val_loss: 2.0640 - val_accuracy: 0.5529\n",
      "Epoch 75/100\n",
      "175/175 [==============================] - 129s 740ms/step - loss: 0.0313 - accuracy: 0.9871 - val_loss: 2.3245 - val_accuracy: 0.5536\n",
      "Epoch 76/100\n",
      "175/175 [==============================] - 116s 663ms/step - loss: 0.0322 - accuracy: 0.9875 - val_loss: 2.2113 - val_accuracy: 0.5457\n",
      "Epoch 77/100\n",
      "175/175 [==============================] - 112s 641ms/step - loss: 0.0334 - accuracy: 0.9859 - val_loss: 2.2400 - val_accuracy: 0.5671\n",
      "Epoch 78/100\n",
      "175/175 [==============================] - 109s 624ms/step - loss: 0.0299 - accuracy: 0.9866 - val_loss: 2.0467 - val_accuracy: 0.5529\n",
      "Epoch 79/100\n",
      "175/175 [==============================] - 120s 685ms/step - loss: 0.0352 - accuracy: 0.9861 - val_loss: 2.2674 - val_accuracy: 0.5586\n",
      "Epoch 80/100\n",
      "175/175 [==============================] - 113s 645ms/step - loss: 0.0338 - accuracy: 0.9866 - val_loss: 2.1740 - val_accuracy: 0.5686\n",
      "Epoch 81/100\n",
      "175/175 [==============================] - 110s 631ms/step - loss: 0.0345 - accuracy: 0.9864 - val_loss: 2.1474 - val_accuracy: 0.5600\n",
      "Epoch 82/100\n",
      "175/175 [==============================] - 111s 635ms/step - loss: 0.0323 - accuracy: 0.9873 - val_loss: 2.1653 - val_accuracy: 0.5650\n",
      "Epoch 83/100\n",
      "175/175 [==============================] - 112s 639ms/step - loss: 0.0329 - accuracy: 0.9850 - val_loss: 2.2149 - val_accuracy: 0.5557\n",
      "Epoch 84/100\n",
      "175/175 [==============================] - 122s 695ms/step - loss: 0.0327 - accuracy: 0.9841 - val_loss: 2.1389 - val_accuracy: 0.5657\n",
      "Epoch 85/100\n",
      "175/175 [==============================] - 128s 732ms/step - loss: 0.0294 - accuracy: 0.9879 - val_loss: 2.4168 - val_accuracy: 0.5500\n",
      "Epoch 86/100\n",
      "175/175 [==============================] - 129s 741ms/step - loss: 0.0343 - accuracy: 0.9855 - val_loss: 2.2069 - val_accuracy: 0.5557\n",
      "Epoch 87/100\n",
      "175/175 [==============================] - 117s 668ms/step - loss: 0.0278 - accuracy: 0.9879 - val_loss: 2.3531 - val_accuracy: 0.5607\n",
      "Epoch 88/100\n",
      "175/175 [==============================] - 111s 635ms/step - loss: 0.0349 - accuracy: 0.9855 - val_loss: 2.2407 - val_accuracy: 0.5679\n",
      "Epoch 89/100\n",
      "175/175 [==============================] - 119s 683ms/step - loss: 0.0281 - accuracy: 0.9886 - val_loss: 2.4589 - val_accuracy: 0.5557\n",
      "Epoch 90/100\n",
      "175/175 [==============================] - 115s 656ms/step - loss: 0.0295 - accuracy: 0.9871 - val_loss: 2.3198 - val_accuracy: 0.5614\n",
      "Epoch 91/100\n",
      "175/175 [==============================] - 124s 711ms/step - loss: 0.0278 - accuracy: 0.9877 - val_loss: 2.2039 - val_accuracy: 0.5571\n",
      "Epoch 92/100\n",
      "175/175 [==============================] - 129s 741ms/step - loss: 0.0298 - accuracy: 0.9868 - val_loss: 2.4249 - val_accuracy: 0.5636\n",
      "Epoch 93/100\n",
      "175/175 [==============================] - 137s 785ms/step - loss: 0.0281 - accuracy: 0.9880 - val_loss: 2.0924 - val_accuracy: 0.5429\n",
      "Epoch 94/100\n",
      "175/175 [==============================] - 112s 641ms/step - loss: 0.0276 - accuracy: 0.9880 - val_loss: 2.2982 - val_accuracy: 0.5586\n",
      "Epoch 95/100\n",
      "175/175 [==============================] - 158s 902ms/step - loss: 0.0332 - accuracy: 0.9877 - val_loss: 2.1453 - val_accuracy: 0.5543\n",
      "Epoch 96/100\n",
      "175/175 [==============================] - 124s 708ms/step - loss: 0.0298 - accuracy: 0.9879 - val_loss: 2.2932 - val_accuracy: 0.5664\n",
      "Epoch 97/100\n",
      "175/175 [==============================] - 119s 679ms/step - loss: 0.0330 - accuracy: 0.9871 - val_loss: 1.9537 - val_accuracy: 0.5629\n",
      "Epoch 98/100\n",
      "175/175 [==============================] - 102s 584ms/step - loss: 0.0261 - accuracy: 0.9879 - val_loss: 2.4940 - val_accuracy: 0.5500\n",
      "Epoch 99/100\n",
      "175/175 [==============================] - 108s 618ms/step - loss: 0.0292 - accuracy: 0.9880 - val_loss: 2.1033 - val_accuracy: 0.5564\n",
      "Epoch 100/100\n",
      "175/175 [==============================] - 117s 668ms/step - loss: 0.0283 - accuracy: 0.9862 - val_loss: 2.2873 - val_accuracy: 0.5593\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(monitor='loss', patience=10)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_pad, y_train, epochs=100, validation_split=0.2, batch_size=32, verbose=1, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_mock_up_data() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m vectorized_tests \u001b[39m=\u001b[39m vectorizer\u001b[39m.\u001b[39mfit_transform(X_test)\n\u001b[0;32m----> 3\u001b[0m X_t_pad, vocab_size \u001b[39m=\u001b[39m get_mock_up_data(vectorized_tests)\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mX_t_pad.shape\u001b[39m\u001b[39m\"\u001b[39m, X_t_pad\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      5\u001b[0m X_t_pad\n",
      "\u001b[0;31mTypeError\u001b[0m: get_mock_up_data() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "vectorized_tests = vectorizer.fit_transform(X_test)\n",
    "\n",
    "X_t_pad, vocab_size = get_mock_up_data(vectorized_tests)\n",
    "print(\"X_t_pad.shape\", X_t_pad.shape)\n",
    "X_t_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-15 11:10:34.345352: W tensorflow/core/framework/op_kernel.cc:1807] OP_REQUIRES failed at cast_op.cc:121 : UNIMPLEMENTED: Cast string to float is not supported\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential/Cast' defined at (most recent call last):\n    File \"/home/anais/.pyenv/versions/3.10.6/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/anais/.pyenv/versions/3.10.6/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/anais/.pyenv/versions/3.10.6/lib/python3.10/asyncio/base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"/home/anais/.pyenv/versions/3.10.6/lib/python3.10/asyncio/base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"/home/anais/.pyenv/versions/3.10.6/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_2099/699147494.py\", line 1, in <module>\n      model.evaluate(X_test,y_test)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/keras/engine/training.py\", line 2072, in evaluate\n      tmp_logs = self.test_function(iterator)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/keras/engine/training.py\", line 1852, in test_function\n      return step_function(self, iterator)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/keras/engine/training.py\", line 1836, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/keras/engine/training.py\", line 1824, in run_step\n      outputs = model.test_step(data)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/keras/engine/training.py\", line 1788, in test_step\n      y_pred = self(x, training=False)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/keras/engine/sequential.py\", line 412, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/keras/engine/functional.py\", line 651, in _run_internal_graph\n      y = self._conform_to_reference_input(y, ref_input=x)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/keras/engine/functional.py\", line 748, in _conform_to_reference_input\n      tensor = tf.cast(tensor, dtype=ref_input.dtype)\nNode: 'sequential/Cast'\nCast string to float is not supported\n\t [[{{node sequential/Cast}}]] [Op:__inference_test_function_99943]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mevaluate(X_test,y_test)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential/Cast' defined at (most recent call last):\n    File \"/home/anais/.pyenv/versions/3.10.6/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/anais/.pyenv/versions/3.10.6/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/anais/.pyenv/versions/3.10.6/lib/python3.10/asyncio/base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"/home/anais/.pyenv/versions/3.10.6/lib/python3.10/asyncio/base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"/home/anais/.pyenv/versions/3.10.6/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_2099/699147494.py\", line 1, in <module>\n      model.evaluate(X_test,y_test)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/keras/engine/training.py\", line 2072, in evaluate\n      tmp_logs = self.test_function(iterator)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/keras/engine/training.py\", line 1852, in test_function\n      return step_function(self, iterator)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/keras/engine/training.py\", line 1836, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/keras/engine/training.py\", line 1824, in run_step\n      outputs = model.test_step(data)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/keras/engine/training.py\", line 1788, in test_step\n      y_pred = self(x, training=False)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/keras/engine/sequential.py\", line 412, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/keras/engine/functional.py\", line 651, in _run_internal_graph\n      y = self._conform_to_reference_input(y, ref_input=x)\n    File \"/home/anais/.pyenv/versions/3.10.6/envs/mood_detector/lib/python3.10/site-packages/keras/engine/functional.py\", line 748, in _conform_to_reference_input\n      tensor = tf.cast(tensor, dtype=ref_input.dtype)\nNode: 'sequential/Cast'\nCast string to float is not supported\n\t [[{{node sequential/Cast}}]] [Op:__inference_test_function_99943]"
     ]
    }
   ],
   "source": [
    "model.evaluate(X_t_pad,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DL using CNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embedding_size = 100\n",
    "model_cnn = Sequential([\n",
    "    layers.Embedding(input_dim=7000, input_dim=vocab_size+1, output_dim=embedding_size, mask_zero=True),\n",
    "    layers.Conv1D(20, kernel_size=3),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "es = EarlyStopping(monitor='loss', patience=1)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_pad, y_train, epochs=100, validation_split=0.2, batch_size=64, verbose=1, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML using SVM classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel='linear', C=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline vectorizer + Naive Bayes\n",
    "pipeline_SVM = make_pipeline(\n",
    "    TfidfVectorizer(), \n",
    "    SVC()\n",
    ")\n",
    "\n",
    "# Cross-validation\n",
    "cv_results = cross_validate(pipeline_SVM, X_train, y_train, cv = 5, scoring = [\"accuracy\"])\n",
    "SVM_average_accuracy = cv_results[\"test_accuracy\"].mean()\n",
    "SVM_accuracy = np.round(SVM_average_accuracy,2)\n",
    "SVM_accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the grid of parameters\n",
    "parameters = {\n",
    "    'SVC__kernel': ('linear', 'poly', 'rbf', 'sigmoid'),\n",
    "    'SVC__C': (0.2, 0.5, 0.7)\n",
    "}\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    parameters,\n",
    "    scoring = \"accuracy\",\n",
    "    cv = 5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best score\n",
    "print(f\"Best Score = {grid_search.best_score_}\")\n",
    "\n",
    "# Best params\n",
    "print(f\"Best params = {grid_search.best_params_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mood_detector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
